"""
Compliance Guard Service.

Ensures legal safety by preventing source code reuse and tracking artifact provenance.
"""

from __future__ import annotations

import difflib
import hashlib
import re
from datetime import datetime
from pathlib import Path
from typing import Any

from pydantic import BaseModel, Field

from ...core.config import get_config
from ...core.exceptions import ComplianceViolationError
from ...core.logging import get_logger
from ...core.types import ServiceResult
from ...storage import StorageBackend

logger = get_logger(__name__)


class ComplianceViolation(BaseModel):
    """A compliance violation record."""

    violation_id: str
    rule_id: str
    severity: str  # critical, warning
    description: str
    artifact_path: str
    detected_at: datetime = Field(default_factory=datetime.utcnow)
    details: dict[str, Any] = Field(default_factory=dict)


class ComplianceReport(BaseModel):
    """Compliance audit report."""

    report_id: str
    run_id: str
    created_at: datetime = Field(default_factory=datetime.utcnow)

    # Results
    passed: bool
    violations: list[ComplianceViolation] = Field(default_factory=list)
    warnings: list[str] = Field(default_factory=list)

    # Audit trail
    artifacts_checked: int = 0
    source_similarity_checks: int = 0
    max_similarity_found: float = 0.0

    # Provenance
    input_hashes: dict[str, str] = Field(default_factory=dict)
    output_hashes: dict[str, str] = Field(default_factory=dict)


class ComplianceInput(BaseModel):
    """Input for compliance check."""

    run_id: str
    apk_hash: str = Field(description="Original APK hash")
    generated_files: dict[str, str] = Field(description="Map of file paths to content")
    decompiled_artifacts: list[str] = Field(default_factory=list, description="Paths to decompiled artifacts to check")


class ComplianceOutput(BaseModel):
    """Output from compliance check."""

    compliance_report: ComplianceReport
    storage_key: str


class ComplianceGuard:
    """Service for ensuring legal compliance.

    This service:
    1. Prevents decompiled source code from being persisted
    2. Checks generated code for similarity to decompiled source
    3. Tracks artifact provenance
    4. Produces audit trails
    """

    def __init__(self, storage: StorageBackend) -> None:
        """Initialize the compliance guard."""
        self.storage = storage
        self.config = get_config().compliance

    # Patterns that indicate code copying
    SUSPICIOUS_PATTERNS = [
        r'// This code was generated by \w+',
        r'// Auto-generated from',
        r'// Decompiled with',
        r'/\* jadx \*/',
        r'/\* JADX',
        r'// Procyon decompiler',
        r'// CFR decompiler',
    ]

    def _normalize_code(self, code: str) -> str:
        """Normalize code for comparison."""
        # Remove comments
        code = re.sub(r'//.*?$', '', code, flags=re.MULTILINE)
        code = re.sub(r'/\*.*?\*/', '', code, flags=re.DOTALL)

        # Remove whitespace
        code = re.sub(r'\s+', ' ', code)

        # Remove string literals (to focus on structure)
        code = re.sub(r'"[^"]*"', '""', code)

        return code.strip().lower()

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity ratio between two texts."""
        norm1 = self._normalize_code(text1)
        norm2 = self._normalize_code(text2)

        if not norm1 or not norm2:
            return 0.0

        return difflib.SequenceMatcher(None, norm1, norm2).ratio()

    def _check_suspicious_patterns(self, content: str) -> list[str]:
        """Check for suspicious patterns in generated code."""
        found = []
        for pattern in self.SUSPICIOUS_PATTERNS:
            if re.search(pattern, content, re.IGNORECASE):
                found.append(pattern)
        return found

    def _compute_content_hash(self, content: str) -> str:
        """Compute hash of content."""
        return hashlib.sha256(content.encode()).hexdigest()

    async def check_artifact_similarity(
        self,
        generated_content: str,
        decompiled_samples: list[str],
        artifact_path: str,
    ) -> tuple[float, list[ComplianceViolation]]:
        """Check if generated content is too similar to decompiled source."""
        violations = []
        max_similarity = 0.0

        for i, sample in enumerate(decompiled_samples):
            similarity = self._calculate_similarity(generated_content, sample)
            max_similarity = max(max_similarity, similarity)

            if similarity > self.config.max_source_similarity_threshold:
                violations.append(ComplianceViolation(
                    violation_id=f"SIM-{i:03d}",
                    rule_id="SOURCE_SIMILARITY",
                    severity="critical",
                    description=f"Generated code has {similarity:.1%} similarity to decompiled source",
                    artifact_path=artifact_path,
                    details={
                        "similarity": similarity,
                        "threshold": self.config.max_source_similarity_threshold,
                        "sample_index": i,
                    },
                ))

        return max_similarity, violations

    async def check_suspicious_content(
        self,
        content: str,
        artifact_path: str,
    ) -> list[ComplianceViolation]:
        """Check for suspicious content in generated code."""
        violations = []

        patterns_found = self._check_suspicious_patterns(content)
        for pattern in patterns_found:
            violations.append(ComplianceViolation(
                violation_id=f"PAT-{len(violations):03d}",
                rule_id="SUSPICIOUS_PATTERN",
                severity="warning",
                description=f"Suspicious pattern found: {pattern}",
                artifact_path=artifact_path,
                details={"pattern": pattern},
            ))

        return violations

    async def verify_no_source_persisted(
        self,
        storage_prefix: str,
    ) -> list[ComplianceViolation]:
        """Verify that no decompiled source is persisted in storage."""
        violations = []

        # Check for common decompiled file patterns
        suspicious_extensions = [".smali", ".jadx", ".class"]
        suspicious_directories = ["smali", "jadx-out", "decompiled", "classes"]

        keys = await self.storage.list_keys(storage_prefix)

        for key in keys:
            # Check file extensions
            for ext in suspicious_extensions:
                if key.endswith(ext):
                    violations.append(ComplianceViolation(
                        violation_id=f"PERSIST-{len(violations):03d}",
                        rule_id="SOURCE_PERSISTED",
                        severity="critical",
                        description=f"Decompiled artifact persisted: {key}",
                        artifact_path=key,
                    ))

            # Check directory patterns
            for dir_pattern in suspicious_directories:
                if f"/{dir_pattern}/" in key or key.startswith(f"{dir_pattern}/"):
                    violations.append(ComplianceViolation(
                        violation_id=f"PERSIST-{len(violations):03d}",
                        rule_id="SOURCE_PERSISTED",
                        severity="critical",
                        description=f"Decompiled directory persisted: {key}",
                        artifact_path=key,
                    ))

        return violations

    async def check(self, input_data: ComplianceInput) -> ServiceResult[ComplianceOutput]:
        """Run compliance checks.

        Args:
            input_data: Compliance check input

        Returns:
            ServiceResult containing ComplianceOutput

        Raises:
            ComplianceViolationError: If critical violations are found and blocking is enabled
        """
        import time
        import uuid

        start_time = time.perf_counter()

        try:
            logger.info("Running compliance checks", run_id=input_data.run_id)

            all_violations: list[ComplianceViolation] = []
            warnings: list[str] = []
            max_similarity = 0.0
            artifacts_checked = 0
            similarity_checks = 0

            # Check each generated file
            for file_path, content in input_data.generated_files.items():
                artifacts_checked += 1

                # Check for suspicious patterns
                pattern_violations = await self.check_suspicious_content(content, file_path)
                all_violations.extend(pattern_violations)

                # Check similarity against decompiled samples (if available)
                if input_data.decompiled_artifacts:
                    decompiled_samples = []
                    for artifact_path in input_data.decompiled_artifacts[:5]:  # Limit checks
                        try:
                            sample = await self.storage.load_text(artifact_path)
                            decompiled_samples.append(sample)
                        except FileNotFoundError:
                            pass

                    if decompiled_samples:
                        similarity, sim_violations = await self.check_artifact_similarity(
                            content, decompiled_samples, file_path
                        )
                        max_similarity = max(max_similarity, similarity)
                        all_violations.extend(sim_violations)
                        similarity_checks += len(decompiled_samples)

            # Check for persisted decompiled source
            persist_violations = await self.verify_no_source_persisted(f"apks/{input_data.apk_hash}")
            all_violations.extend(persist_violations)

            # Compute output hashes for provenance
            output_hashes = {
                path: self._compute_content_hash(content)
                for path, content in input_data.generated_files.items()
            }

            # Determine pass/fail
            critical_violations = [v for v in all_violations if v.severity == "critical"]
            passed = len(critical_violations) == 0

            # Create report
            report = ComplianceReport(
                report_id=str(uuid.uuid4()),
                run_id=input_data.run_id,
                passed=passed,
                violations=all_violations,
                warnings=warnings,
                artifacts_checked=artifacts_checked,
                source_similarity_checks=similarity_checks,
                max_similarity_found=max_similarity,
                input_hashes={"apk": input_data.apk_hash},
                output_hashes=output_hashes,
            )

            # Store report
            storage_key = f"compliance/{input_data.run_id}/compliance_report.json"
            await self.storage.store_model(storage_key, report)

            # Block if configured and violations found
            if not passed and self.config.block_on_violation:
                raise ComplianceViolationError(
                    message=f"Compliance check failed with {len(critical_violations)} critical violations",
                    rule_id="COMPLIANCE_BLOCK",
                    violation_type="critical",
                    context={"violations": [v.model_dump() for v in critical_violations[:5]]},
                )

            output = ComplianceOutput(
                compliance_report=report,
                storage_key=storage_key,
            )

            duration_ms = (time.perf_counter() - start_time) * 1000
            logger.info(
                "Compliance check completed",
                passed=passed,
                violations=len(all_violations),
                max_similarity=max_similarity,
                duration_ms=duration_ms,
            )

            return ServiceResult.ok(output, duration_ms=duration_ms)

        except ComplianceViolationError:
            raise
        except Exception as e:
            logger.error("Compliance check failed", error=str(e))
            return ServiceResult.fail(str(e))

    async def audit_run(self, run_id: str) -> ComplianceReport | None:
        """Retrieve compliance report for a run."""
        try:
            key = f"compliance/{run_id}/compliance_report.json"
            return await self.storage.load_model(key, ComplianceReport)
        except FileNotFoundError:
            return None
